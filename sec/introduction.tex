\section{Introduction}
\label{sec:intro}


Foundation models for 3D data have emerged as a new paradigm for large-scale 3D shape understanding. Inspired by the success of self-supervised learning in natural language and vision, several transformer-based architectures have been adapted to 3D modalities such as point clouds, meshes, and voxels. These models learn expressive representations from unlabeled data and have achieved strong performance across tasks including classification, segmentation, and shape retrieval. The ability to extract rich, semantically meaningful features without manual supervision marks a significant step toward general-purpose 3D understanding.

Despite this progress, a key question remains open: \textit{What do 3D encoders learn about the structural properties of shapes?} While most studies have focused on evaluating semantic or geometric performance, little is known about whether these representations also capture deeper structural information such as topology. This limitation reflects a broader issue in the adaptation of self-supervised paradigms to 3D data. Pretraining strategies originally designed for text or 2D images have been directly transferred to 3D shapes, often without considering their unique mathematical and geometric properties. As a result, current models display restricted generalization. Encoders trained on object-centric datasets struggle to extend to large-scale scenes, whereas scene-level encoders often miss fine-grained shape details. Understanding the nature and limitations of these learned representations is therefore essential to assess whether these models truly capture intrinsic shape structure or simply memorize patterns present in their training distribution.

\subsection{Current State of Research}

Seminal work on self-supervised 3D encoders such as Point-BERT~\cite{pbert} and Point-MAE~\cite{pmae} have shown that transformer-based architectures can effectively model local and global geometric cues. They rely on masked modeling, or token reconstruction objectives to build shape embeddings. These embeddings have been empirically shown to correlate with geometric and semantic properties, yet they are rarely evaluated with respect to the topological structure of the underlying shape. Topology encodes the intrinsic organization of a shape beyond its local geometry. Capturing such information would indicate that a model understands the global connectivity and multi-scale structure of a 3D object, which is critical for robust generalization.

Topological Data Analysis (TDA) provides a mathematically principled framework for describing such structure. Through persistent homology, TDA quantifies the evolution of topological features such as connected components, loops, and voids as a scale parameter varies. These features form persistence diagrams, which summarize the underlying shape topology. TDA has been successfully used in physics, biology, and shape analysis~\cite{top_signatures} to measure structural complexity. However, it suffers from high computational cost: persistent homology scales poorly with both sample size and dimensionality, making it difficult to apply directly to modern 3D datasets with millions of points or high-resolution geometry.

Recent work has begun exploring connections between deep learning and TDA\cite{optimizing_persistent_homology, persistent_homology_seg, }. Neural networks can learn topological signatures~\cite{atol}, approximate persistence diagrams \cite{neural_approximation_graph_topological_features}, or embed topological features into latent spaces~\cite{topological_autoencoders}. Conversely, topological descriptors have been used to regularize or interpret neural representations~\cite{top_layer, topology_activations, top_reg}. However, few studies have investigated whether large pretrained 3D encoders implicitly learn topological information in their latent representations, and how this information compares to the explicit characterization provided by TDA.

\subsection{Motivations}

The goal of this report is to bridge the gap between representation learning and topological analysis for 3D shapes. There are three main motivations behind this work.

First, understanding how 3D shape encoders capture topology is fundamental to interpreting their learned representations. If these models encode persistent topological features, this would provide evidence that large-scale self-supervised training implicitly organizes representations around structural properties of shapes, not just visual or semantic correlations.

Second, topological data analysis offers a principled framework to quantify structural awareness. By comparing the topological signatures derived from a model’s latent space to those computed directly from geometry, we can evaluate whether the learned representations preserve key structural information. This enables a new kind of interpretability analysis grounded in topology.

Third, the connection can be turned the other way around. If 3D transformers already encode topological information, their representations could serve as efficient, data-driven proxies for topological computations. Since persistent homology is computationally expensive for large or high-dimensional datasets, learning-based approximations based on pretrained representations could scale topological reasoning to complex real-world 3D data.

The central problem investigated in this report can be summarized as follows:

\begin{center}
    \fbox{\parbox{0.9\linewidth}{
    \textit{To what extent do current 3D shape encoders capture the topological structure of 3D shapes, and can their learned representations be leveraged as scalable proxies for topological computations?}
    }}
\end{center}

Addressing this question contributes both to the interpretability of 3D foundation models and to the development of efficient topology-aware methods for large-scale geometric data.

\subsection{Contributions}

The contributions of this report are three-fold:

\begin{itemize}
    \item \textbf{A topology-controlled dataset.} We introduce DONUT (Section \ref{sec:topogen}), a scalable dataset of 3D shapes with full control over their topological properties. This dataset enables systematic evaluation of models’ sensitivity to structural variations.
    \item \textbf{A quantitative analysis of structural awareness.} We perform comprehensive experiments to measure how state-of-the-art unimodal 3D shape encoders capture structural, non-semantic information (Sections \ref{sec:used_models} and \ref{sec:ph}). Using persistent homology as an analytical tool, we assess the topological consistency of learned embeddings.
    \item \textbf{Architectural and training insights.} Based on the findings, we propose directions for improving 3D shape encoders, including architectural modifications and pretraining strategies that encourage topology-aware representations.
\end{itemize}