\section{Introduction}
\label{sec:intro}


Foundation models for 3D data have emerged as a new paradigm for large-scale 3D shape understanding. Inspired by the success of self-supervised learning in natural language and vision, several transformer-based architectures have been adapted to 3D modalities such as point clouds, meshes, and voxels. These models learn expressive representations from unlabeled data and have achieved strong performance across tasks including classification, segmentation, and shape retrieval. The ability to extract rich, semantically meaningful features without manual supervision marks a significant step toward general-purpose 3D understanding.

Despite this progress, a key question remains open: \textit{What do 3D encoders learn about the structural properties of shapes?} While most studies have focused on evaluating semantic or geometric performance, little is known about whether these representations also capture deeper structural information such as topology. This limitation reflects a broader issue in the adaptation of self-supervised paradigms to 3D data. Pretraining strategies originally designed for text or 2D images have been directly transferred to 3D shapes, often without considering their unique mathematical and geometric properties. As a result, current models display restricted generalization. Encoders trained on object-centric datasets struggle to extend to large-scale scenes, whereas scene-level encoders often miss fine-grained shape details. Understanding the nature and limitations of these learned representations is therefore essential to assess whether these models truly capture intrinsic shape structure or simply memorize patterns present in their training distribution.

\subsection{Current State of Research}

Early self-supervised 3D encoders such as Point-BERT~\cite{pbert} and Point-MAE~\cite{pmae} showed that transformers can model local and global geometric cues in point clouds. They rely on masked modeling or token reconstruction to learn shape embeddings that capture semantic and geometric structure. However, these embeddings are rarely evaluated with respect to the topology of shapes.

Topology describes how a shape is connected, regardless of geometric detail. It captures invariants such as connected components, loops, or voids that remain unchanged under continuous deformations. Understanding whether 3D encoders represent such properties is key to knowing if they learn intrinsic structure rather than only geometry or semantics.

Topological Data Analysis (TDA) provides a mathematical framework to study these properties. Through persistent homology, TDA tracks the evolution of topological features as a scale parameter changes, summarizing them in persistence diagrams. These diagrams have been used in physics, biology, and shape analysis~\cite{top_signatures} to measure structural complexity, but they remain costly to compute as their complexity grows quickly with sample size and dimension.

Recent studies have tried to bridge TDA and deep learning~\cite{optimizing_persistent_homology, persistent_homology_seg, }. Neural networks can learn topological signatures~\cite{atol}, approximate persistence diagrams \cite{neural_approximation_graph_topological_features}, or embed topological features into latent spaces~\cite{topological_autoencoders}. Conversely, topological descriptors have been used to regularize or interpret neural representations~\cite{top_layer, topology_activations, top_reg}. Yet, few works have explored whether large pretrained 3D transformers already encode topological information implicitly and how this compares to explicit TDA descriptors. This question motivates the present work.

\subsection{Motivations}

This work aims to connect representation learning and topological analysis for 3D shapes. Three main motivations guide our study.

understanding whether 3D shape encoders capture topology is central to interpreting what they learn. If persistent topological features can be recovered from their embeddings, this would suggest that large self-supervised models organize information according to structural properties rather than only geometric and semantic ones.

Second, topological data analysis offers a principled framework to quantify structural awareness. By comparing the topological signatures derived from a model’s latent space to those computed directly from 3D shapes, we can evaluate whether the learned representations preserve key structural information. This enables a new kind of interpretability analysis grounded in topology.

Third, if encoders already contain topological information, their representations could serve as efficient, data-driven proxies for topological computations. Since persistent homology is computationally expensive for large or high-dimensional datasets, learning-based approximations based on pretrained representations could scale topological reasoning to complex real-world 3D data.

We therefore ask:

\begin{center}
    \fbox{\parbox{0.9\linewidth}{
    \textit{To what extent do current 3D shape encoders capture the topological structure of 3D shapes, and can their learned representations be leveraged as scalable proxies for topological computations?}
    }}
\end{center}

Addressing this question contributes both to the interpretability of 3D foundation models and to the development of efficient topology-aware methods for large-scale geometric data.

\subsection{Contributions}

The contributions of this report are three-fold:

\begin{itemize}
    \item \textbf{A topology-controlled dataset.} We introduce DONUT (Section \ref{sec:topogen}), a scalable dataset of 3D shapes with full control over their topological properties. This dataset enables systematic evaluation of models’ sensitivity to structural variations.
    \item \textbf{A quantitative analysis of structural awareness.} We perform comprehensive experiments to measure how state-of-the-art unimodal 3D shape encoders capture structural, non-semantic information (Sections \ref{sec:used_models} and \ref{sec:experiments}). Using persistent homology as an analytical tool, we assess the topological consistency of learned embeddings.
    \item \textbf{Architectural and training insights.} Based on the findings, we propose directions for improving 3D shape encoders, including architectural modifications and pretraining strategies that encourage topology-aware representations.
\end{itemize}